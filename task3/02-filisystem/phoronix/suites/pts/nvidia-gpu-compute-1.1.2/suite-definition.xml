<?xml version="1.0"?>
<!--Phoronix Test Suite v10.0.0m2-->
<PhoronixTestSuite>
  <SuiteInformation>
    <Title>NVIDIA GPU Compute</Title>
    <Version>1.1.2</Version>
    <TestType>Graphics</TestType>
    <Description>A collection of test profiles that run well on NVIDIA GPU systems with CUDA / proprietary driver stack. Other deprecated / less interesting / older tests not included but this test suite is intended to serve as guidance for current interesting NVIDIA GPU compute benchmarking albeit not exhaustive of what is available via Phoronix Test Suite / OpenBenchmarking.org.</Description>
    <Maintainer>Michael Larabel</Maintainer>
  </SuiteInformation>
  <Execute>
    <Test>pts/hashcat</Test>
    <Mode>BATCH</Mode>
  </Execute>
  <Execute>
    <Test>pts/fahbench</Test>
  </Execute>
  <Execute>
    <Test>pts/gromacs</Test>
    <Mode>BATCH</Mode>
    <OptionSelect>implementation = NVIDIA CUDA GPU</OptionSelect>
  </Execute>
  <Execute>
    <Test>pts/namd-cuda</Test>
    <Mode>BATCH</Mode>
  </Execute>
  <Execute>
    <Test>pts/mixbench</Test>
    <Arguments>mixbench-ocl-ro SPGFLOPS</Arguments>
    <Description>Backend: OpenCL - Benchmark: Single Precision</Description>
  </Execute>
  <Execute>
    <Test>pts/mixbench</Test>
    <Arguments>mixbench-ocl-ro DPGFLOPS</Arguments>
    <Description>Backend: OpenCL - Benchmark: Double Precision</Description>
  </Execute>
  <Execute>
    <Test>pts/mixbench</Test>
    <Arguments>mixbench-ocl-ro GIOPS</Arguments>
    <Description>Backend: OpenCL - Benchmark: Integer</Description>
  </Execute>
  <Execute>
    <Test>pts/mixbench</Test>
    <Arguments>mixbench-cuda-ro SPGFLOPS</Arguments>
    <Description>Backend: NVIDIA CUDA - Benchmark: Single Precision</Description>
  </Execute>
  <Execute>
    <Test>pts/mixbench</Test>
    <Arguments>mixbench-cuda-ro DPGFLOPS</Arguments>
    <Description>Backend: NVIDIA CUDA - Benchmark: Double Precision</Description>
  </Execute>
  <Execute>
    <Test>pts/mixbench</Test>
    <Arguments>mixbench-cuda-ro HPGFLOPS</Arguments>
    <Description>Backend: NVIDIA CUDA - Benchmark: Half Precision</Description>
  </Execute>
  <Execute>
    <Test>pts/mixbench</Test>
    <Arguments>mixbench-cuda-ro GIOPS</Arguments>
    <Description>Backend: NVIDIA CUDA - Benchmark: Integer</Description>
  </Execute>
  <Execute>
    <Test>pts/octanebench</Test>
    <Description>Total Score</Description>
  </Execute>
  <Execute>
    <Test>pts/luxcorerender</Test>
    <Mode>BATCH</Mode>
    <OptionSelect>accel = GPU</OptionSelect>
  </Execute>
  <Execute>
    <Test>pts/rodinia</Test>
    <Arguments>OCL_PARTICLEFILTER</Arguments>
    <Description>Test: OpenCL Particle Filter</Description>
  </Execute>
  <Execute>
    <Test>pts/arrayfire</Test>
    <Arguments>cg_opencl</Arguments>
    <Description>Test: Conjugate Gradient OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/clpeak</Test>
    <Arguments>--global-bandwidth</Arguments>
    <Description>OpenCL Test: Global Memory Bandwidth</Description>
  </Execute>
  <Execute>
    <Test>pts/clpeak</Test>
    <Arguments>--compute-sp</Arguments>
    <Description>OpenCL Test: Single-Precision Float</Description>
  </Execute>
  <Execute>
    <Test>pts/clpeak</Test>
    <Arguments>--compute-dp</Arguments>
    <Description>OpenCL Test: Double-Precision Double</Description>
  </Execute>
  <Execute>
    <Test>pts/clpeak</Test>
    <Arguments>--compute-integer</Arguments>
    <Description>OpenCL Test: Integer Compute INT</Description>
  </Execute>
  <Execute>
    <Test>pts/neatbench</Test>
    <Arguments>gpu</Arguments>
    <Description>Acceleration: GPU</Description>
  </Execute>
  <Execute>
    <Test>pts/financebench</Test>
    <Arguments>Black-Scholes/OpenCL/blackScholesAnalyticEngine.exe</Arguments>
    <Description>Benchmark: Black-Scholes OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/plaidml</Test>
    <Arguments>--fp16 --no-train mobilenet OPENCL</Arguments>
    <Description>FP16: Yes - Mode: Inference - Network: Mobilenet - Device: OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/plaidml</Test>
    <Arguments>--no-fp16 --train mobilenet OPENCL</Arguments>
    <Description>FP16: No - Mode: Training - Network: Mobilenet - Device: OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/plaidml</Test>
    <Arguments>--no-fp16 --no-train mobilenet OPENCL</Arguments>
    <Description>FP16: No - Mode: Inference - Network: Mobilenet - Device: OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/plaidml</Test>
    <Arguments>--no-fp16 --no-train densenet201 OPENCL</Arguments>
    <Description>FP16: No - Mode: Inference - Network: DenseNet 201 - Device: OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/plaidml</Test>
    <Arguments>--no-fp16 --no-train imdb_lstm OPENCL</Arguments>
    <Description>FP16: No - Mode: Inference - Network: IMDB LSTM - Device: OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/lczero</Test>
    <Arguments>-b opencl</Arguments>
    <Description>Backend: OpenCL</Description>
  </Execute>
  <Execute>
    <Test>pts/cl-mem</Test>
    <Arguments>READ</Arguments>
    <Description>Benchmark: Read</Description>
  </Execute>
  <Execute>
    <Test>pts/cl-mem</Test>
    <Arguments>WRITE</Arguments>
    <Description>Benchmark: Write</Description>
  </Execute>
  <Execute>
    <Test>pts/cl-mem</Test>
    <Arguments>COPY</Arguments>
    <Description>Benchmark: Copy</Description>
  </Execute>
  <Execute>
    <Test>pts/mandelgpu</Test>
    <Arguments>0 1</Arguments>
    <Description>OpenCL Device: GPU</Description>
  </Execute>
  <Execute>
    <Test>pts/viennacl</Test>
    <Mode>BATCH</Mode>
  </Execute>
  <Execute>
    <Test>pts/shoc</Test>
    <Mode>BATCH</Mode>
  </Execute>
  <Execute>
    <Test>pts/redshift</Test>
  </Execute>
  <Execute>
    <Test>pts/indigobench</Test>
    <Arguments>--gpuonly --scenes supercar</Arguments>
    <Description>Acceleration: OpenCL GPU - Scene: Supercar</Description>
  </Execute>
  <Execute>
    <Test>pts/indigobench</Test>
    <Arguments>--gpuonly --scenes bedroom</Arguments>
    <Description>Acceleration: OpenCL GPU - Scene: Bedroom</Description>
  </Execute>
  <Execute>
    <Test>pts/v-ray</Test>
    <Arguments>-m vray-gpu-cuda</Arguments>
    <Description>Mode: NVIDIA CUDA GPU</Description>
  </Execute>
  <Execute>
    <Test>pts/v-ray</Test>
    <Arguments>-m vray-gpu-rtx</Arguments>
    <Description>Mode: NVIDIA RTX GPU</Description>
  </Execute>
  <Execute>
    <Test>pts/blender</Test>
    <Mode>BATCH</Mode>
    <OptionSelect>compute = CUDA, compute = NVIDIA OptiX</OptionSelect>
  </Execute>
  <Execute>
    <Test>pts/caffe</Test>
    <Mode>BATCH</Mode>
    <OptionSelect>accel = NVIDIA CUDA</OptionSelect>
  </Execute>
  <Execute>
    <Test>pts/vulkan-compute</Test>
  </Execute>
</PhoronixTestSuite>
